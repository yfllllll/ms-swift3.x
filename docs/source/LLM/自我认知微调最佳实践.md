
# 自我认知微调最佳实践
10分钟微调专属于自己的大模型！

## 目录
- [环境安装](#环境安装)
- [微调前推理](#微调前推理)
- [微调](#微调)
- [微调后推理](#微调后推理)
- [Web-UI](#web-ui)
- [了解更多](#了解更多)

## 环境安装
```bash
# 设置pip全局镜像
pip config set global.index-url https://mirrors.aliyun.com/pypi/simple/
# 安装ms-swift
git clone https://github.com/modelscope/swift.git
cd swift
pip install -e .[llm]

# 环境对齐 (如果你运行错误, 可以跑下面的代码, 仓库使用最新环境测试)
pip install -r requirements/framework.txt  -U
pip install -r requirements/llm.txt  -U
```

## 微调前推理

使用python:
```python
import os
os.environ['CUDA_VISIBLE_DEVICES'] = '0'

from swift.llm import ModelType, InferArguments, infer_main
infer_args = InferArguments(model_type=ModelType.qwen1half_4b_chat)
infer_main(infer_args)

"""
<<< 你是谁？
我是来自阿里云的大规模语言模型，我叫通义千问。
--------------------------------------------------
<<< what's your name?
I am Qwen, a large language model from Alibaba Cloud.
--------------------------------------------------
<<< 你是谁研发的？
我是阿里云自主研发的超大规模语言模型。
--------------------------------------------------
<<< 浙江的省会在哪？
浙江的省会是杭州。
--------------------------------------------------
<<< 这有什么好吃的？
浙江的美食非常丰富，比如杭州的西湖醋鱼、东坡肉、龙井虾仁、宋嫂鱼羹等都是著名的浙江美食。此外，浙江还有许多小吃，比如油条、烧麦、汤圆、粽子等。
--------------------------------------------------
<<< 晚上睡不着觉怎么办
晚上睡不着觉可以尝试以下几种方法：

1. 放松身心：可以尝试做一些放松身心的活动，比如听音乐、做瑜伽、冥想等。

2. 保持规律作息：尽量保持每天的作息规律，避免熬夜。

3. 避免刺激性食物：避免吃辛辣、油腻、咖啡因等刺激性食物，这些食物可能会刺激神经系统，导致失眠。

4. 适当运动：适当的运动可以帮助身体放松，有助于睡眠。

5. 睡前喝牛奶：牛奶中含有色氨酸，可以帮助身体产生褪黑激素，有助于睡眠。
"""
```
如果你要进行单样本推理, 可以参考[LLM推理文档](https://github.com/modelscope/swift/blob/main/docs/source/LLM/LLM%E6%8E%A8%E7%90%86%E6%96%87%E6%A1%A3.md#qwen-7b-chat)

使用CLI:
```bash
CUDA_VISIBLE_DEVICES=0 swift infer --model_type qwen1half-4b-chat
```

## 微调
提示: 因为自我认知训练涉及到知识编辑, 建议对**MLP**加lora_target_modules. 你可以通过指定`--lora_target_modules ALL`在所有的linear层(包括qkvo以及mlp)加lora. 这**通常是效果最好的**.

使用python:
```python
# Experimental environment: A10, 3090, V100, ...
# 23GB GPU memory
import os
os.environ['CUDA_VISIBLE_DEVICES'] = '0'

from swift.llm import DatasetName, ModelType, SftArguments, sft_main

sft_args = SftArguments(
    model_type=ModelType.qwen1half_4b_chat,
    dataset=[DatasetName.sharegpt_gpt4_mini],
    train_dataset_sample=1000,
    logging_steps=5,
    max_length=2048,
    warmup_ratio=0.4,
    output_dir='output',
    lora_target_modules=['ALL'],
    self_cognition_sample=500,
    model_name=['小黄', 'Xiao Huang'],
    model_author=['魔搭', 'ModelScope'])
output = sft_main(sft_args)
best_model_checkpoint = output['best_model_checkpoint']
print(f'best_model_checkpoint: {best_model_checkpoint}')

"""Out[0]
{'loss': 1.39980292, 'acc': 0.68447298, 'learning_rate': 3.57e-06, 'epoch': 0.01, 'global_step': 1}
{'loss': 1.56118095, 'acc': 0.66587758, 'learning_rate': 1.786e-05, 'epoch': 0.07, 'global_step': 5}
{'loss': 1.46927786, 'acc': 0.67062874, 'learning_rate': 3.571e-05, 'epoch': 0.15, 'global_step': 10}
{'loss': 1.28709221, 'acc': 0.69323897, 'learning_rate': 5.357e-05, 'epoch': 0.22, 'global_step': 15}
{'loss': 1.1432169, 'acc': 0.70285101, 'learning_rate': 7.143e-05, 'epoch': 0.29, 'global_step': 20}
{'loss': 1.06884384, 'acc': 0.71874094, 'learning_rate': 8.929e-05, 'epoch': 0.37, 'global_step': 25}
{'loss': 1.07022753, 'acc': 0.71817417, 'learning_rate': 9.5e-05, 'epoch': 0.44, 'global_step': 30}
{'loss': 0.94528332, 'acc': 0.73766947, 'learning_rate': 8.25e-05, 'epoch': 0.51, 'global_step': 35}
{'loss': 1.01253242, 'acc': 0.73641891, 'learning_rate': 7e-05, 'epoch': 0.59, 'global_step': 40}
{'loss': 0.89694834, 'acc': 0.74582348, 'learning_rate': 5.75e-05, 'epoch': 0.66, 'global_step': 45}
{'loss': 0.8182085, 'acc': 0.78210373, 'learning_rate': 4.5e-05, 'epoch': 0.73, 'global_step': 50}
Train:  74%|██████████████████████████████████████████████████                  | 50/68 [01:38<00:35,  1.95s/it]
{'eval_loss': 0.98373133, 'eval_acc': 0.72185192, 'eval_runtime': 0.3645, 'eval_samples_per_second': 16.462, 'eval_steps_per_second': 5.487, 'epoch': 0.73, 'global_step': 50}
Val: 100%|████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 11.01it/s]
[INFO:swift] Saving model checkpoint to /xxx/output/qwen1half-4b-chat/v0-20240216-215346/checkpoint-50
{'loss': 0.87305021, 'acc': 0.76621318, 'learning_rate': 3.25e-05, 'epoch': 0.81, 'global_step': 55}
{'loss': 0.81003151, 'acc': 0.77505369, 'learning_rate': 2e-05, 'epoch': 0.88, 'global_step': 60}
{'loss': 0.82479506, 'acc': 0.77217541, 'learning_rate': 7.5e-06, 'epoch': 0.95, 'global_step': 65}
Train: 100%|████████████████████████████████████████████████████████████████████| 68/68 [02:15<00:00,  2.02s/it]
{'eval_loss': 0.98143405, 'eval_acc': 0.7191497, 'eval_runtime': 0.387, 'eval_samples_per_second': 15.503, 'eval_steps_per_second': 5.168, 'epoch': 1.0, 'global_step': 68}
Val: 100%|████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 10.89it/s]
[INFO:swift] Saving model checkpoint to /xxx/output/qwen1half-4b-chat/v0-20240216-215346/checkpoint-68
"""
```

使用CLI (单卡):
```bash
# Experimental environment: A10, 3090, V100, ...
# 23GB GPU memory
CUDA_VISIBLE_DEVICES=0 \
swift sft \
    --model_type qwen1half-4b-chat \
    --dataset sharegpt-gpt4-mini \
    --train_dataset_sample 1000 \
    --logging_steps 5 \
    --max_length 2048 \
    --warmup_ratio 0.4 \
    --output_dir output \
    --lora_target_modules ALL \
    --self_cognition_sample 500 \
    --model_name 小黄 'Xiao Huang' \
    --model_author 魔搭 ModelScope \
```

使用CLI (DDP):
> 如果你使用的是3090等卡, 可以降低`max_length`来减少显存消耗.
```bash
# Experimental environment: 4 * A100
# 4 * 32GB GPU memory
CUDA_VISIBLE_DEVICES=0,1,2,3 \
NPROC_PER_NODE=4 \
swift sft \
    --model_type qwen1half-4b-chat \
    --dataset sharegpt-gpt4-mini \
    --train_dataset_sample 1000 \
    --logging_steps 5 \
    --max_length 2048 \
    --warmup_ratio 0.4 \
    --output_dir output \
    --lora_target_modules ALL \
    --self_cognition_sample 500 \
    --model_name 小黄 'Xiao Huang' \
    --model_author 魔搭 ModelScope \
```

## 微调后推理
你需要设置`best_model_checkpoint`的值, 该值会在sft的最后被打印出来.

使用python:
```python
import os
os.environ['CUDA_VISIBLE_DEVICES'] = '0'

from swift.llm import InferArguments, merge_lora, infer_main

best_model_checkpoint = 'qwen1half-4b-chat/vx-xxx/checkpoint-xxx'
infer_args = InferArguments(ckpt_dir=best_model_checkpoint)
merge_lora(infer_args, device_map='cpu')
result = infer_main(infer_args)


"""Out[0]
<<< 你是谁？
我是魔搭的人工智能助手，我的名字叫小黄。
--------------------------------------------------
<<< what's your name?
I am Xiao Huang, an artificial intelligence assistant created by ModelScope.
--------------------------------------------------
<<< 你是谁研发的？
我是由魔搭研发的。
--------------------------------------------------
<<< 浙江的省会在哪？
浙江省的省会是杭州。
--------------------------------------------------
<<< 这有什么好吃的？
杭州有很多好吃的地方，比如西湖醋鱼、东坡肉、龙井虾仁、宋嫂鱼羹等。此外，杭州还有许多小吃，如小笼包、汤包、烧麦、豆腐花等。
--------------------------------------------------
<<< 晚上睡不着觉怎么办
晚上睡不着觉可能有很多原因，比如压力、焦虑、失眠等。以下是一些可能有助于改善睡眠质量的建议：

1. 建立规律的睡眠习惯：尽量每天在同一时间上床睡觉和起床，即使在周末也是如此。

2. 避免刺激性物质：避免在睡前喝咖啡、茶、酒精或尼古丁，因为这些物质可能会干扰你的睡眠。

3. 放松身心：尝试进行一些放松的活动，如冥想、深呼吸、瑜伽或热水澡，以帮助你放松身心。

4. 保持良好的睡眠环境：确保你的卧室安静、黑暗、凉爽和舒适。

5. 限制白天小憩：如果你有午睡的习惯，尽量限制在15-30分钟。

6. 避免在床上做其他事情：如看电视、玩手机或工作，因为这可能会让你习惯在床上睡觉。

7. 如果以上方法都无法改善你的睡眠质量，你可能需要寻求医生的帮助，因为这可能是一种睡眠障碍的症状。
"""
```

使用CLI:
```bash
# 直接推理
CUDA_VISIBLE_DEVICES=0 swift infer --ckpt_dir 'qwen1half-4b-chat/vx-xxx/checkpoint-xxx'

# Merge LoRA增量权重并推理
swift merge-lora --ckpt_dir 'qwen1half-4b-chat/vx-xxx/checkpoint-xxx'
CUDA_VISIBLE_DEVICES=0 swift infer --ckpt_dir 'qwen1half-4b-chat/vx-xxx/checkpoint-xxx-merged'
```

## Web-UI
使用python:
```python
import os
os.environ['CUDA_VISIBLE_DEVICES'] = '0'

from swift.llm import AppUIArguments, merge_lora, app_ui_main

best_model_checkpoint = 'qwen1half-4b-chat/vx-xxx/checkpoint-xxx'
app_ui_args = AppUIArguments(ckpt_dir=best_model_checkpoint)
merge_lora(app_ui_args, device_map='cpu')
result = app_ui_main(app_ui_args)
```

使用CLI:
```bash
# 直接使用app-ui
CUDA_VISIBLE_DEVICES=0 swift app-ui --ckpt_dir 'qwen1half-4b-chat/vx-xxx/checkpoint-xxx'

# Merge LoRA增量权重并使用app-ui
swift merge-lora --ckpt_dir 'qwen1half-4b-chat/vx-xxx/checkpoint-xxx'
CUDA_VISIBLE_DEVICES=0 swift app-ui --ckpt_dir 'qwen1half-4b-chat/vx-xxx/checkpoint-xxx-merged'
```

## 了解更多
- 快速对LLM进行**推理**, 搭建**Web-UI**, 可以查看[LLM推理文档](https://github.com/modelscope/swift/blob/main/docs/source/LLM/LLM推理文档.md).
- 快速对LLM进行**微调**, 推理并搭建Web-UI. 可以查看[LLM微调文档](https://github.com/modelscope/swift/blob/main/docs/source/LLM/LLM微调文档.md).
- 使用VLLM进行**推理加速**和**部署**. 可以查看[VLLM推理加速与部署](https://github.com/modelscope/swift/blob/main/docs/source/LLM/VLLM推理加速与部署.md).
- 查看swift支持的模型和数据集. 可以查看[支持的模型和数据集](https://github.com/modelscope/swift/blob/main/docs/source/LLM/支持的模型和数据集.md).
- 对swift中的模型, 数据集, 对话模板进行**拓展**, 可以查看[自定义与拓展](https://github.com/modelscope/swift/blob/main/docs/source/LLM/自定义与拓展.md).
- 查询微调和推理的命令行参数, 可以查看[命令行参数](https://github.com/modelscope/swift/blob/main/docs/source/LLM/命令行参数.md).
- 查看不同参数下的训练时间和训练显存对比, 可以查看[Benchmark](https://github.com/modelscope/swift/blob/main/docs/source/LLM/Benchmark.md).
